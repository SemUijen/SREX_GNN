{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_features = 2\n",
    "hidden_dim = 64\n",
    "num_heads = 8\n",
    "num_encoder_layers = 2\n",
    "initial_layer = nn.Linear(num_features, hidden_dim)\n",
    "max_routes_to_swap = 90\n",
    "route_combination_head = nn.Linear(2 * hidden_dim, max_routes_to_swap + 1)\n",
    "transformer = nn.TransformerEncoder(\n",
    "    nn.TransformerEncoderLayer(hidden_dim, num_heads),\n",
    "    num_encoder_layers\n",
    ")\n",
    "number_of_customers = 15\n",
    "\n",
    "# Simple 15 nodes with 2 features\n",
    "graph_p1 = torch.rand(number_of_customers, num_features)\n",
    "graph_p2 = torch.rand(number_of_customers, num_features)\n",
    "\n",
    "\n",
    "# for ease of testing just a simple layer\n",
    "P1_emmbedding = initial_layer(graph_p1)\n",
    "P2_emmbedding = initial_layer(graph_p2)\n",
    "print(\"Embedding Shape: \", P1_emmbedding.shape)\n",
    "\n",
    "\n",
    "## Parent 1\n",
    "P1_number_of_routes = 6\n",
    "P1_Cnode_to_route = torch.tensor([0, 0, 0, 1, 1, 2, 2, 3, 3, 4, 4, 4, 5, 5, 5])\n",
    "P1_node_to_route_matrix = torch.zeros(number_of_customers, P1_number_of_routes)\n",
    "P1_node_to_route_matrix[torch.arange(number_of_customers), P1_Cnode_to_route] = 1\n",
    "\n",
    "\n",
    "## Parent 2\n",
    "P2_number_of_routes = 4\n",
    "P2_Cnode_to_route = torch.tensor([0, 0, 0, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3])\n",
    "P2_node_to_route_matrix = torch.zeros(number_of_customers, P2_number_of_routes)\n",
    "P2_node_to_route_matrix[torch.arange(number_of_customers), P2_Cnode_to_route] = 1\n",
    "\n",
    "\n",
    "P1_route_aggregating = torch.matmul(P1_node_to_route_matrix.t(), P1_emmbedding)\n",
    "P2_route_aggregating = torch.matmul(P2_node_to_route_matrix.t(), P2_emmbedding)\n",
    "print(\"Parent 1 Route features: \", P1_route_aggregating.shape)\n",
    "print(\"Parent 2 Route features: \", P2_route_aggregating.shape)\n",
    "\n",
    "a, b = torch.broadcast_tensors(P1_route_aggregating[:, None], P1_route_aggregating[None, :])\n",
    "parent_route_combination_representations = torch.cat((a, b), -1)\n",
    "print(\"parent_route_combo: \", parent_route_combination_representations.shape)\n",
    "\n",
    "max_to_swap = min(P1_number_of_routes, P2_number_of_routes)\n",
    "full_prediction = route_combination_head(parent_route_combination_representations)\n",
    "print(\"Full prediction shape: \", full_prediction.shape)\n",
    "\n",
    "# Actual size of the allowed matrix =  (P1_number_of_routes, P2_number_of_routes, max_to_swap)\n",
    "logits = full_prediction[:P1_number_of_routes, :P2_number_of_routes, :max_to_swap + 1]\n",
    "probs = torch.softmax(logits.flatten(), -1).view_as(logits)\n",
    "\n",
    "print('Output: ', probs.shape, probs.sum())\n",
    "\n",
    "\n",
    "highest_prob = probs.max()\n",
    "SREX_param = torch.where(probs == highest_prob)\n",
    "print(f\"best SrexParams: P1x = {SREX_param[0].item()}, P2x = {SREX_param[1].item()}, NumRoutesMove = {SREX_param[2].item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "num_features = 2\n",
    "hidden_dim = 64\n",
    "num_heads = 8\n",
    "num_encoder_layers = 2\n",
    "initial_layer = nn.Linear(num_features, hidden_dim)\n",
    "max_routes_to_swap = 90\n",
    "route_combination_head = nn.Linear(2 * hidden_dim, max_routes_to_swap + 1)\n",
    "transformer = nn.TransformerEncoder(\n",
    "    nn.TransformerEncoderLayer(hidden_dim, num_heads),\n",
    "    num_encoder_layers\n",
    ")\n",
    "\n",
    "graph_batch_left_parent = torch.rand(15, 2)\n",
    "graph_batch_right_parent = torch.rand(15, 2)\n",
    "\n",
    "\n",
    "hidden_left = initial_layer(graph_batch_left_parent)\n",
    "out = hidden_left\n",
    "\"\"\"\n",
    "# apply transformer per graph in batch\n",
    "out = torch.zeros_like(hidden_left)\n",
    "for batch_idx in range(3):\n",
    "    # get nodes from batch\n",
    "    hidden_batch = hidden_left[node_to_graph_left == batch_idx, :]\n",
    "    out[node_to_graph_left == batch_idx, :] = transformer(hidden_batch)\n",
    "\n",
    "# apply transformer per route in batch\n",
    "out = torch.zeros_like(hidden_left)\n",
    "for route_idx in range(6): # loop over routes\n",
    "    # get nodes from batch\n",
    "    hidden_batch = hidden_left[node_to_route_left == route_idx, :]\n",
    "    out[node_to_route_left == route_idx, :] = transformer(hidden_batch)\"\"\"\n",
    "\n",
    "# out = transformer(hidden, node_to_graph1) # use pytorch.geometric\n",
    "\n",
    "# transformer(hidden).shape\n",
    "\n",
    "graph_idx = torch.tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2])\n",
    "\n",
    "batch_size = 3\n",
    "# parents1 = 3 routes, 2 routes, 1 route\n",
    "# parents = [\n",
    "#   [[0, 1, 2], [3, 4], [5, 6]], # route 0, 1, 2\n",
    "#   [[7, 8], [9, 10, 11]], # route 3, 4\n",
    "#   [[12, 13, 14]] # route 5\n",
    "# ]\n",
    "\n",
    "node_to_route1 = torch.tensor([0, 0, 0, 1, 1, 2, 2, 3, 3, 4, 4, 4, 5, 5, 5])\n",
    "route_to_graph1 = torch.tensor([0, 0, 0, 1, 1, 2])\n",
    "node_to_graph1 = route_to_graph1[node_to_route1]\n",
    "\n",
    "\n",
    "\n",
    "# parents2\n",
    "route_to_graph = []\n",
    "\n",
    "node_to_route = torch.tensor([0, 0, 0, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3])\n",
    "node_to_route2 = torch.tensor([0, 0, 0, 0, 1, 1, 1, 1])\n",
    "\n",
    "def indices_to_matrix(indices):\n",
    "    matrix = torch.zeros(len(indices), indices.max())\n",
    "\n",
    "number_of_customers = 15\n",
    "number_of_routes = 6\n",
    "node_to_route_matrix = torch.zeros(number_of_customers,number_of_routes)\n",
    "node_to_route_matrix[torch.arange(number_of_customers), node_to_route1] = 1\n",
    "node_to_route_matrix\n",
    "\n",
    "# node_to_route_matrix2 = torch.zeros(8, 2)\n",
    "# node_to_route_matrix2[torch.arange(8), node_to_route2] = 1\n",
    "# node_to_route_matrix2\n",
    "\n",
    "route_hidden_left = torch.matmul(node_to_route_matrix.t(), out)\n",
    "route_hidden_right = torch.matmul(node_to_route_matrix.t(), out)\n",
    "\n",
    "route_to_graph_left = route_to_graph1\n",
    "route_to_graph_right = route_to_graph_left\n",
    "\n",
    "for batch_idx in range(3):  # loop over batch\n",
    "    routes_left = route_hidden_left[route_to_graph_left == batch_idx, :]\n",
    "    routes_right = route_hidden_right[route_to_graph_right == batch_idx, :]\n",
    "    print(\"Couple: \", batch_idx,\"Parent1_routes: \", routes_left[:, None].shape, \"Parent2_routes: \",routes_right[None, :].shape)\n",
    "\n",
    "    a, b = torch.broadcast_tensors(routes_left[:, None], routes_right[None, :])\n",
    "    parent_route_combination_representations = torch.cat((a, b), -1)\n",
    "    print(\"parent_route_combo: \", parent_route_combination_representations.shape)\n",
    "\n",
    "    max_to_swap = min(routes_left.shape[0], routes_right.shape[0])\n",
    "    full_prediction = route_combination_head(parent_route_combination_representations)\n",
    "    print(\"Full prediction shape: \", full_prediction.shape)\n",
    "    logits = full_prediction[:, :, :max_to_swap + 1]\n",
    "\n",
    "    # print(result.shape)\n",
    "    probs = torch.softmax(logits.flatten(), -1).view_as(logits)\n",
    "\n",
    "    print('Output: ', probs.shape, probs.sum())\n",
    "    print(\"\")\n",
    "    training_label = torch.rand(*probs.shape)  # performance score for option\n",
    "    training_probs = torch.softmax(logits.flatten(), -1).view_as(logits)\n",
    "\n",
    "    #loss = torch.cross_entropy(probs.flatten(), training_probs.flatten())\n",
    "    # or something like\n",
    "    # loss = torch.cross_entropy_with_logits(logits.flatten(), torch.softmax(training_labels.flatten()))\n",
    "\n",
    "    # result[i, j, k] # unnormalized probability for starting at route i from\n",
    "    # parent left and route j from parent right swapping k routes (may be 0)\n",
    "\n",
    "    # print(a.shape, b.shape)\n",
    "    # print(torch.cat((a, b), -1).shape)\n",
    "    # route_combination_head"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
